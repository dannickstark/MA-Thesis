\section{Conception\label{sec:conception}}

This chapter describes the solution concept and all aspects that were investigated to derive it.
The investigation includes the following activities:

First, the problem statement from \textbf{Chapter \ref{sec:introduction}} is revisited and further refined using information derived from concrete use cases, internal documents, and relevant literature.
Then, the elicited information is analyzed in detail to derive customization operations and criteria for the evaluation and selection of appropriate customization mechanisms that have been introduced in \textbf{Chapter \ref{sec:foundation}}. Finally, the solution concept is formalized.\\



\subsection{Refined Problem Statement}
This thesis aims to address the challenges of configuring simulations in the automotive industry through the use of semantic technology. The focus is on the development of an expert system that utilizes the metadata of existing simulations to facilitate the creation of new simulations. This solution aims to streamline the configuration process and make it more efficient and accessible, especially for inexperienced simulation engineers.

Here are a few use cases that can be derived from the problem raised by this thesis.

\begin{itemize}
    \item \textbf{New simulation configuration}: When a new simulation needs to be created, the system suggests relevant configurations based on previous simulations with similar goals or constraints, leveraging the semantic relationships embedded in the metadata. This can significantly reduce configuration time and ensure consistency with best practices.
    \item \textbf{Knowledge transfer}: The system serves as a knowledge repository that captures and stores information about previous simulations and their configurations. This allows new engineers to access valuable insights and learn from previous projects, shortening the learning curve and promoting knowledge sharing within the team.
    \item \textbf{Error prevention}: Semantic validation rules ensure that new configurations adhere to the defined guidelines and restrictions. This avoids errors and inconsistencies that could lead to inaccurate simulation results.
    \item \textbf{Configuration optimization}: The system can analyze previous simulation data and suggest optimized configurations based on performance metrics, allowing engineers to achieve better results with less effort.
\end{itemize}


\subsection{Simulation's Architecture \label{subsec:sim-archi}}
\textbf{Figure \ref{fig:cea-proc}} shows a general problem-solving diagram, illustrating how a problem might be handled using CAE methods. Above each phase is the sequence of different steps.\\

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/Concept-cae-process.drawio.png}
    \caption[The CAE Core Process, Illustrated with the Stages of a General Problem-Solving Scheme.]{\label{fig:cea-proc}  The CAE Core Process, Illustrated with the Stages of a General Problem-Solving Scheme. \cite{assistSim}}
\end{figure}

Based on the elements and steps involved in this process, a simulation ontology will be created. This will enable us to capture and formalize the elements involved in the configuration process, as well as the interdependencies between them. Particularly important in the context of this thesis are the elements involved in the “Definition” and “Composition” stages, as these lead to a "CAE-Model". \textbf{Figure \ref{fig:uml-sim}} shows a UML diagram representing the information extracted from \textbf{Figure \ref{fig:cea-proc}} and the relationships between them.\\

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/UML-Sim.png}
    \caption{\label{fig:uml-sim}  UML Representation of the Simulation’s Metadata}
\end{figure}


\subsection{Simulation Modeling Using Ontology}
The modeling of a domain does not adhere to a singular proper approach, as there are consistently viable alternatives. The optimal method typically relies on the specific application and extensions you intend to implement. Ontology development is an iterative process \cite{noy2001ontology}. The connection between ontology ideas and things, whether physical or logical, as well as the relationships within one's field of study, is essential. In the phrases characterizing your domain, it is quite probable that these items are nouns (things) or verbs (relations). As presented in \textbf{Section \ref{para:sms_analysis}}, the researchers behind the “Protégé” software have put together a set of best practices, which will be followed in this work \cite{noy2001ontology}. The steps to follow are:

\begin{itemize}
    \item \textbf{Step 1}: Scope Definition
    \item \textbf{Step 2}: Reuse Existing Vocabulary
    \item \textbf{Step 3}: Identification of Important Terms
    \item \textbf{Step 4}: Class Hierarchy and Taxonomy
    \item \textbf{Step 5}: Define Attributes and Properties of Classes — Slots
    \item \textbf{Step 6}: Define the Facets of the Slots
    \item \textbf{Step 7}: Creation of Instances
\end{itemize}

    \subsubsection{Step 1: Scope Definition}
    The development of an ontology begins with the definition of its domain and field of application. To do this, a few questions need to be answered \cite{noy2001ontology}:
    
    \begin{itemize}
        \item What domain will the ontology cover? 
        \item For what purpose will we utilize the ontology? 
        \item To what kinds of queries should the knowledge in the ontology offer answers? 
        \item Who will utilize and maintain the ontology?
    \end{itemize}
    
    The answers to these questions have already been partially addressed in our previous analysis. In this thesis, an ontology will be created to model simulations and their metadata used during configuration. The ontology aims to provide a formalism for the elements involved in the configuration process and to model the relationships and interdependencies between these elements. Different simulation templates will be stored in the ontology, and information about them can be accessed using SPARQL queries (explained in \textbf{Section \ref{para:sparql}}). This will enable a suitable algorithm to assist future users. The ontology will be used primarily by simulation engineers. It will be maintained by an expert in semantic technology and expert simulation engineers, who will enrich it with their knowledge.

    
    \subsubsection{Step 2: Reuse Existing Vocabulary}
    Setting up an ontology from scratch can be a rather tedious and complex process, requiring a certain level of knowledge in the target domain. That's why it's worth investigating whether there's a similar ontology to the one you want to build, which can be extended and refined to meet your requirements 100\%. Numerous ontologies are available in electronic form on the Internet. Platforms such as \textbf{DBPedia}, \textbf{WikiData} or \textbf{Linked Open Vocabularies (LOV)} allow you to access free ontologies, download them and integrate them into other ontologies.\\
    
    During the study in \textbf{Chapter \ref{sec:relwork}}, some simulation ontologies were identified. These include: OSMO \cite{horsch2021osmo}, I2Sim \cite{grolinger2012ontology}, OntologySim \cite{may2022ontology} and VIO \cite{spelten2023simulation}. Unfortunately, given that the elements we want to model (see \textbf{Figure \ref{fig:cea-proc}}) come from conventions defined as part of the EP4.0 project \cite{assistSim}, it was impossible to find a free ontology that could cover our needs. The ontology will therefore have to be built from scratch, using the structure described in \textbf{Figure \ref{fig:uml-sim}}.


    \subsubsection{Step 3: Identification of Important Terms}
    All the important terms can be extracted from the diagram in \textbf{Figure \ref{fig:uml-sim}}. The most important are:
    
    \begin{itemize}
        \item LoadCase Template
        \item LoadCase
        \item Basic Model
        \item Core Model
        \item Numeric 
        \item Solver
        \item Physical Basic Structure
        \item Mathematical Basic Structure
        \item Logical Basic Structure
        \item Task
    \end{itemize}

    
    \subsubsection{Step 4: Class Hierarchy and Taxonomy}
    There are three main techniques for building a class hierarchy.
    \begin{itemize}
        \item \textbf{A top-down development}: this approach starts by formulating the broadest principles of the field, which are then further refined through specialization.

        \item \textbf{A bottom-up development}: the process starts with establishing the precise classifications within the hierarchy, followed by categorizing these classifications into more general concepts.
        
        \item \textbf{A combination development}: this method combines the two previous approaches. The most important ideas are first identified. They are then generalized and specified as appropriate.
    \end{itemize}
    
    For this thesis, the third (hybrid) approach is the most appropriate. Since the majority of key elements have already been defined (top-down), it remains to group those of the same type into more generic notions (bottom-up). The various intermediate elements/classes are presented in \textbf{Figure \ref{fig:classi-pack}}, \textbf{Figure \ref{fig:classi-model}}, \textbf{Figure \ref{fig:classi-basic-struct}}:
    
    \begin{figure}[h]
        \centering
            \begin{tikzpicture} 
            \centering
            \umlsimpleclass{Package} 
            \umlsimpleclass[x=-2, y=-2, anchor=north]{LoadCaseTemplate} 
            \umlsimpleclass[x=2, y=-2, anchor=north]{LoadCase} 
            \umlVHVinherit[arm2=-1.2cm]{LoadCaseTemplate}{Package} 
            \umlVHVinherit[arm2=-1.2cm]{LoadCase}{Package} 
            \end{tikzpicture} 
        \caption{\label{fig:classi-pack} Classification of “Package”}
    \end{figure}
    
    \begin{figure}[h]
        \centering
            \begin{tikzpicture} 
            \centering
            \umlsimpleclass{Model} 
            \umlsimpleclass[x=-2, y=-2, anchor=north]{BasicModel} 
            \umlsimpleclass[x=2, y=-2, anchor=north]{CoreModel} 
            \umlVHVinherit[arm2=-1.2cm]{BasicModel}{Model} 
            \umlVHVinherit[arm2=-1.2cm]{CoreModel}{Model} 
            \end{tikzpicture} 
        \caption{\label{fig:classi-model} Classification of “Model”}
    \end{figure}
    
    \begin{figure}[h]
        \centering
            \begin{tikzpicture} 
            \centering
            \umlsimpleclass{BasicStructure} 
            \umlsimpleclass[x=-2, y=-2, anchor=north]{PhysicalBasicStructure} 
            \umlsimpleclass[x=4, y=-2, anchor=north]{MathematicalBasicStructure}  
            \umlsimpleclass[x=10, y=-2, anchor=north]{LogicalBasicStructure} 
            \umlVHVinherit[arm2=-1.2cm]{PhysicalBasicStructure}{BasicStructure} 
            \umlVHVinherit[arm2=-1.2cm]{MathematicalBasicStructure}{BasicStructure} 
            \umlVHVinherit[arm2=-1.2cm]{LogicalBasicStructure}{BasicStructure} 
            \end{tikzpicture} 
        \caption{\label{fig:classi-basic-struct} Classification of “BasicStructure”}
    \end{figure}
    

    
    \subsubsection{Step 5: Define Attributes and Properties of Classes — Slots}
    To achieve a complete, connected knowledge model, the properties of the various classes and the relationships between these classes still need to be explicitly defined. Here again, our UML diagram in \textbf{Figure \ref{fig:uml-sim}} comes into play. It contains the definition of each class and its properties.
    
    
    \subsubsection{Step 6: Define the Facets of the Slots}
    Slots can have many facets that describe the type of value, the permitted values, the number of values (cardinality), and other characteristics of the values the slot can accept. A facet can be a string, a number, a Boolean literal, or an instance of a class. The “range” represents the classes authorized for the value of a property. The “domain” represents the classes that a property can describe. The diagram in \textbf{Figure \ref{fig:uml-sim}} also shows the relationships between the various classes, as well as their cardinalities.
    
    
    \subsubsection{Step 7: Creation of Instances}
    For our purposes, instances will be created using a migration system when our server is first launched (see \textbf{Chapter \ref{sec:implementation}}).
    

\subsection{\acrlong{cbr} \label{subsec:cbr}}
\acrfull{cbr} is an approach to building intelligent systems that model the way humans think. \textbf{Figure \ref{fig:simple-cbr}} shows a simplified model of \acrshort{cbr}. This method involves recording experiences in the form of cases. These cases are then retrieved and reused (partially, fully, or modified) to solve new problems. The new experience acquired in this way will in turn be stored in the memory and will later help in the resolution of a new case. It's therefore a cycle following several stages. \textbf{Figure \ref{fig:cbr-cycle}} shows the \acrshort{cbr} cycle. The stages making up this cycle are as follows and will be explained in more detail in the following sections.
    
    \begin{enumerate}
        \item Retrieve
        \item Reuse
        \item Revise
        \item Retain
    \end{enumerate}
    
    \begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/Concept-simplified-cbr-Simplified CBR princip.drawio.png}
    \caption[Simplified Model of CBR]{\label{fig:simple-cbr}  Simplified Model of CBR \cite{probSolCBR}}
    \end{figure}
    
    \begin{figure}[h]
    \centering
    \includegraphics[scale=0.6]{images/Concept-cbr-cycle.png}
    \caption[CBR Cycle]{\label{fig:cbr-cycle}  CBR Cycle \cite{cbrIntroRecent}}
    \end{figure}
    

    \subsection{Retrieve}
    The aim here is to find the case(s) in the database most similar to the query, taking into account certain similarity functions or criteria. The key question here is how to measure similarity between 2 entities. This will be studied in greater depth in \textbf{Section \ref{subsec:similarity}}. The problem that can quickly arise here is that, over time, as the database of cases increases, the efficiency of the search decreases. This is because numerous cases have to be examined to find the most similar ones. There is therefore a sub-field of \acrshort{cbr} research that focuses on methods to improve search efficiency. One example is the use of special index structures such as “kd-trees”, case-finding networks, or discrimination networks \cite{cbrIntroRecent}.
    
    \subsection{Reuse}
    Once similar cases have been obtained, the answer (or any other information relating to the solution of the problem) from these cases is used to deal with the current problem. There are two types of reuse: simple reuse and reuse with adaptation. 
    
    \begin{itemize}
        \item \textbf{Simple reuse} involves using the recovered answer as a suggested solution for the new problem, without modification. This method is much better suited to classification work, which involves a few solutions but many cases.  For this scenario, all potential solutions are already present in the case base, so adaptation is generally not necessary. 
        
        \item \textbf{Reuse with adaptation} is necessary for synthetic tasks such as planning or configuration. For these tasks, the number of possible solutions far exceeds the number of available examples (or is even infinite).
    \end{itemize}

    Numerous adaptation proposals have been put forward within the \acrshort{cbr} framework. The primary distinction among these various adaption approaches is in their classification as either transformational or generative.
    
    \begin{itemize}
        \item Transformational adaptation is based on a set of adaptation rules or operators, which specify how variations in the problem lead to the necessary changes in the solution.  
        
        \item Generative adaptation requires the use of a generative problem solver such as LLM. The latter must possess the ability to overcome challenges by utilizing broad knowledge. Here, it's not the case solutions that are used, but the path (reasoning) taken to obtain these solutions. 
    \end{itemize}

    Adaptation can be a tedious process. This is why the majority of work in the field of \acrshort{cbr} seeks to avoid or reduce the modifications to be made once an interesting case has been obtained.


    \subsection{Revise}
    This stage provides feedback on the solution. The aim is to determine whether the solution works and is relevant, through verification in simulations or the real world. This feedback can take the form of an accuracy score.
    
    
    \subsection{Retain}
    This phase represents the learning phase of the \acrshort{cbr} system. In a \acrshort{cbr} system, learning consists of adding a new case, generally by modifying a case already in the case base. This new case then becomes available for use in future problem-solving processes.\\
    However, as mentioned above, the constant expansion of the case base can at some point create a utility problem, as it reduces the efficiency of the search. Researchers have devised special algorithms for learning similarity measures. Early techniques focused on the use of feature weights \cite{cbrIntroRecent}. But more recent methods tackle the more difficult task of using local and global similarity functions \cite{shaheen2020novel, jaiswal2022f}. 

    
    
    \subsection{Similarity\label{subsec:similarity}}
    As presented in the retrieve step, the main concept of \acrshort{cbr} is similarity. This is because the cases chosen during the process are those most similar to the current situation (query). Similarity can be formalized by a function $sim: P \times P \rightarrow [0, 1]$, which compares two problem descriptions of type \textbf{P} and returns a score between 0 and 1. The higher this score, the more similar the two problems are considered to be \cite{cbrIntroRecent}.\\
    For a new problem \textbf{p}, a case $c_1 = (p_1, s_1)$ is more appropriate than a case $c_2 = (p_2, s_2)$ (represented by $c_1 \succ_p c_2$) \textbf{iff} $sim(p, p_2) < sim(p, p_3)$. Here, the exact value of the similarities is not the most important factor, but the fact that these values allow us to give an order of relevance between the different cases considered. This order of preference corresponds to the evaluation of the usefulness of these cases for the treatment of problem \textbf{p} during the reuse phase.\\
    
    The local-global approach, first introduced by Richter \cite{richter2008similarity, richter2013basic}, is the most widely implemented. \textbf{Figure \ref{fig:cbr-exam}} shows an example of similarity calculation using this principle. Here, cases are represented by graphs, in which each \textbf{Node} has attributes $A_i$ of different types $T_i$. For each Node, a local calculation is first performed at the level of these attributes, using a similarity function $_i = sim_{A_i} : T_i \times T_i$ according to the type of attribute. The local similarities are then combined to calculate the global similarity using an appropriate combination. The combination adopted is called the \textbf{amalgamation function: F}, and also takes into account the different weights of the attributes. There are several amalgamation functions:
    
    \begin{itemize}
        \item \textbf{Weighted Average}: $F(s_1,...,s_n)= \sum_{1=1}^{n} w_i*s_i$
        \item \textbf{Maximum}: $F(s_1,...,s_n) = max\{s_1,...,s_n\}$
        \item \textbf{k-Minimum}: $F(s_1,...,s_n) = s_{ik} \quad with \quad s_{i1} \leq s_{i2} \leq ... \leq s_{in}$
    \end{itemize}
    
    The global similarity can therefore be described mathematically as follows:\\
    \[sim(x,y) = sim((x_1,...,x_n),(y_1,...,y_n)) = F(sim_{A_1}(x_1, y_1),..., sim_{A_n}(x_n, y_n) )\] where \[F: [0,1]_n \rightarrow [0,1]\].\\


    \begin{figure}[h]
    \centering
    \includegraphics[scale=0.6]{images/Concept-CBR Exemple.drawio.png}
    \caption{\label{fig:cbr-exam}  Calculation of Similarity Using the Local-Global Principle}
    \end{figure}
    
    \begin{itemize}
        \item $sim_{price}$ is calculated using a \textbf{linear numerical measurement}. The function used is $(n_1, n_2) \rightarrow 1 - abs(n_1 - n_2) / (n_1 + n_2)$. This gives a value of 0.943
        \item for $sim_{color}$ the \textbf{string equality measure} is used. Since \textbf{red != green} the obtained value is 0.
        \item $sim_{fuel}$ is calculated using a string equality measure. Since \textbf{Petrol != Diesel} we obtain a value of 0
        \item $sim_{cylinder}$ is calculated using linear numeric measure. Since they two values are equal, we have a similarity of 1.
        \item $sim(X_2, Y_2)$ is obtained by aggregating the similarities of the Fuel and Cylinders attributes with equal weighting. $sim(X_2, Y_2) = \frac{1}{2} * 0 + \frac{1}{2} * 1 = 0.5$
        \item $sim_{name}$ is calculated using a \textbf{taxonomic similarity measure} based on a semantic taxonomy \cite{malburg2021improving}.
        \item $sim(X_1, Y_1) = 1 * 0.4 = 0.4$
        \item finally $sim(X, Y) = \frac{1}{4} sim_{price} + \frac{1}{4} sim_{color} + \frac{1}{4} sim(X_1, Y_1) + \frac{1}{4} sim(X_2, Y_2) = 0.46$ \\
    \end{itemize}

Once the architecture of the solution to be developed has been established, and the mathematical aspects involved in the reasoning process have been understood, the next chapter will focus on implementation. In this chapter, appropriate technologies will have to be chosen to implement the previously defined architecture, and a presentation of the algorithms following the above mathematical concepts will be presented and explained.\\